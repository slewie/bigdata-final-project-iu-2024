{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4f4ab8-ad2e-4068-9969-2d03ef612f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417c1a4a-c23f-4cba-98a6-18014e1ea248",
   "metadata": {},
   "source": [
    "# Connect to Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77c9c5c-5669-4044-ae05-653505054630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Add here your team number teamx\n",
    "team = 'team27'\n",
    "\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372dabdc-dfbb-4684-ac32-a24e53971537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://hadoop-01.uni.innopolis.ru:4141\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>team27 - spark ML</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fbadfcd3e80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b32e1-d448-4489-9ded-2da995dd9482",
   "metadata": {},
   "source": [
    "# list Hive databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0520078-be98-492b-be87-22055e657a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Database(name='default', description='Default Hive database', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/apps/hive/warehouse'), Database(name='root_db', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/root/root_db'), Database(name='team0_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team0/project/hive/warehouse'), Database(name='team12_hive_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team12/project/hive/warehouse'), Database(name='team13_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team13/project/hive/warehouse'), Database(name='team14_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team14/project/hive/warehouse'), Database(name='team15_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team15/project/hive/warehouse'), Database(name='team16_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team16/project/hive/warehouse'), Database(name='team17_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team17/project/hive/warehouse'), Database(name='team18_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team18/project/hive/warehouse'), Database(name='team19_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team19/project/hive/warehouse'), Database(name='team1_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team1/project/hive/warehouse'), Database(name='team20_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team20/project/hive/warehouse'), Database(name='team21_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team21/project/hive/warehouse'), Database(name='team22_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team22/project/hive/warehouse'), Database(name='team23_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team23/project/hive/warehouse'), Database(name='team24_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team24/project/hive/warehouse'), Database(name='team25_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team25/project/hive/warehouse'), Database(name='team26_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse'), Database(name='team27_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team27/project/hive/warehouse'), Database(name='team28_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team28/project/hive/warehouse'), Database(name='team29_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team29/project/hive/warehouse'), Database(name='team2_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team2/project/hive/warehouse'), Database(name='team30_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team30/project/hive/warehouse'), Database(name='team31_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team31/project/hive/warehouse'), Database(name='team3_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team3/project/hive/warehouse'), Database(name='team4_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team4/project/hive/warehouse'), Database(name='team5_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team5/project/hive/warehouse'), Database(name='team6_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team6/project/hive/warehouse'), Database(name='team7_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team7/project/hive/warehouse'), Database(name='team8_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team8/project/hive/warehouse'), Database(name='team9_projectdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/user/team9/project/hive/warehouse'), Database(name='testdb', description='', locationUri='hdfs://hadoop-02.uni.innopolis.ru:8020/apps/hive/warehouse/testdb.db')]\n",
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             root_db|\n",
      "|     team0_projectdb|\n",
      "|team12_hive_proje...|\n",
      "|    team13_projectdb|\n",
      "|    team14_projectdb|\n",
      "|    team15_projectdb|\n",
      "|    team16_projectdb|\n",
      "|    team17_projectdb|\n",
      "|    team18_projectdb|\n",
      "|    team19_projectdb|\n",
      "|     team1_projectdb|\n",
      "|    team20_projectdb|\n",
      "|    team21_projectdb|\n",
      "|    team22_projectdb|\n",
      "|    team23_projectdb|\n",
      "|    team24_projectdb|\n",
      "|    team25_projectdb|\n",
      "|    team26_projectdb|\n",
      "|    team27_projectdb|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(spark.catalog.listDatabases())\n",
    "spark.sql(\"SHOW DATABASES;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f0b7dd-3af6-423f-a89c-ceb8f8fdb86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='authors', database='team27_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q1_results', database='team27_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q2_results', database='team27_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q3_results', database='team27_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q4_results', database='team27_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q5_results', database='team27_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='reviews', database='team27_projectdb', description=None, tableType='EXTERNAL', isTemporary=False)]\n"
     ]
    }
   ],
   "source": [
    "print(spark.catalog.listTables(\"team27_projectdb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0de9f8-7f6a-4460-84d5-816a2154744f",
   "metadata": {},
   "source": [
    "# Read hive tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99dbc9f7-8b5a-4011-bc5d-39864e2a24dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = spark.read.format(\"avro\").table('team27_projectdb.authors')\n",
    "\n",
    "reviews = spark.read.format(\"avro\").table('team27_projectdb.reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4734f0f-8d12-4970-816e-1a331eb604eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-----------+\n",
      "|          steamid|num_games|num_reviews|\n",
      "+-----------------+---------+-----------+\n",
      "|76561198017400473|      239|        191|\n",
      "|76561198012915042|      382|        168|\n",
      "|76561198057849347|      394|        146|\n",
      "|76561198138147736|      366|         80|\n",
      "|76561198352226102|      164|         70|\n",
      "+-----------------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authors.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af92fb3-cacf-45b9-8f34-7b39392ee71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+---------+--------+--------------------+-----------------+-----------------+-------------+-----------+-------------------+-------------+--------------+-----------------+---------------------------+-----------------+----------------+-----------------------+------------------+-----------+-----------+\n",
      "|      id|app_id|       appname|review_id|language|              review|time_date_created|time_date_updated|votes_helpful|votes_funny|weighted_vote_score|comment_count|steam_purchase|received_for_free|written_during_early_access|   author_steamid|playtime_forever|playtime_last_two_weeks|playtime_at_review|last_played|recommended|\n",
      "+--------+------+--------------+---------+--------+--------------------+-----------------+-----------------+-------------+-----------+-------------------+-------------+--------------+-----------------+---------------------------+-----------------+----------------+-----------------------+------------------+-----------+-----------+\n",
      "|20270143|524220|NieR:Automata™| 85124293| english|This game is so b...|       2021-01-22|       2021-01-22|            0|          0| 0.4330708384513855|            0|          true|            false|                      false|76561198838897166|           128.0|                    0.0|             128.0| 2018-12-14|      false|\n",
      "|20269649|524220|NieR:Automata™| 30576526| english|I liked the game ...|       2017-03-17|       2017-04-06|            1|          0| 0.5035824179649353|            0|          true|            false|                      false|76561198007330588|          1405.0|                    0.0|            1405.0| 2017-04-03|      false|\n",
      "|20269608|524220|NieR:Automata™| 30576800| english|First time with t...|       2017-03-17|       2017-03-17|            9|          3| 0.0783192664384841|            0|          true|            false|                      false|76561198015397037|            30.0|                    0.0|              30.0| 2017-03-17|      false|\n",
      "|20269606|524220|NieR:Automata™| 30576805|  french|Le jeu est moyenn...|       2017-03-17|       2019-03-03|            0|          0|                0.0|            0|         false|            false|                      false|76561198057156972|           260.0|                    0.0|             260.0| 2018-06-24|      false|\n",
      "|20269191|524220|NieR:Automata™| 30580501| english|A sequel to Plati...|       2017-03-18|       2017-03-19|           25|          3| 0.5133581161499025|           25|          true|            false|                      false|76561197962082784|          1589.0|                    0.0|            1589.0| 2017-03-25|      false|\n",
      "+--------+------+--------------+---------+--------+--------------------+-----------------+-----------------+-------------+-----------+-------------------+-------------+--------------+-----------------+---------------------------+-----------------+----------------+-----------------------+------------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd4f769-73ec-4895-a946-df63e3f8bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      " id                          | 20270143                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      " app_id                      | 524220                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
      " appname                     | NieR:Automata™                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
      " review_id                   | 85124293                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
      " language                    | english                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
      " review                      | This game is so bad I couldn't even finish it. In fact, I had to force my friend to play it for me to the very end so I could analyze its crisp and crunchy shittiness to the finest detail.\\n\\nIf Metal Gear Rising was watered-down Bayonetta, then this is its bastard child. Sepia-toned colorless world, confusing soundtrack, useless gameplay mechanics (an illusion of equipment choices, for example) and an unbalanced dodge-fest of bullets, changing camera angles and genres that make no sense at all. \n",
      " time_date_created           | 2021-01-22                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " time_date_updated           | 2021-01-22                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " votes_helpful               | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " votes_funny                 | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " weighted_vote_score         | 0.4330708384513855                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
      " comment_count               | 0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " steam_purchase              | true                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
      " received_for_free           | false                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      " written_during_early_access | false                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      " author_steamid              | 76561198838897166                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
      " playtime_forever            | 128.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      " playtime_last_two_weeks     | 0.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
      " playtime_at_review          | 128.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      " last_played                 | 2018-12-14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
      " recommended                 | false                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.show(1, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0afbc090-4f8a-4556-95ce-12ac6492008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of `authors` dataset: (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of `authors` dataset:\", (authors.count(), len(authors.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c34ca27c-5688-4578-9191-9eb922b8a52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of `reviews` dataset: (203518, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of `reviews` dataset:\", (reviews.count(), len(reviews.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bec56fe-e9b6-42a9-80a4-c04c6729fab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+--------------+---------+--------+--------------------+-----------------+-----------------+-------------+-----------+-------------------+-------------+--------------+-----------------+---------------------------+-----------------+----------------+-----------------------+------------------+-----------+-----------+-----------------+---------+-----------+\n",
      "|      id|app_id|       appname|review_id|language|              review|time_date_created|time_date_updated|votes_helpful|votes_funny|weighted_vote_score|comment_count|steam_purchase|received_for_free|written_during_early_access|   author_steamid|playtime_forever|playtime_last_two_weeks|playtime_at_review|last_played|recommended|          steamid|num_games|num_reviews|\n",
      "+--------+------+--------------+---------+--------+--------------------+-----------------+-----------------+-------------+-----------+-------------------+-------------+--------------+-----------------+---------------------------+-----------------+----------------+-----------------------+------------------+-----------+-----------+-----------------+---------+-----------+\n",
      "|20270143|524220|NieR:Automata™| 85124293| english|This game is so b...|       2021-01-22|       2021-01-22|            0|          0| 0.4330708384513855|            0|          true|            false|                      false|76561198838897166|           128.0|                    0.0|             128.0| 2018-12-14|      false|76561198838897166|      107|         76|\n",
      "|20269649|524220|NieR:Automata™| 30576526| english|I liked the game ...|       2017-03-17|       2017-04-06|            1|          0| 0.5035824179649353|            0|          true|            false|                      false|76561198007330588|          1405.0|                    0.0|            1405.0| 2017-04-03|      false|76561198007330588|      301|        108|\n",
      "|20269608|524220|NieR:Automata™| 30576800| english|First time with t...|       2017-03-17|       2017-03-17|            9|          3| 0.0783192664384841|            0|          true|            false|                      false|76561198015397037|            30.0|                    0.0|              30.0| 2017-03-17|      false|76561198015397037|      344|         84|\n",
      "|20269606|524220|NieR:Automata™| 30576805|  french|Le jeu est moyenn...|       2017-03-17|       2019-03-03|            0|          0|                0.0|            0|         false|            false|                      false|76561198057156972|           260.0|                    0.0|             260.0| 2018-06-24|      false|76561198057156972|      266|         82|\n",
      "|20269191|524220|NieR:Automata™| 30580501| english|A sequel to Plati...|       2017-03-18|       2017-03-19|           25|          3| 0.5133581161499025|           25|          true|            false|                      false|76561197962082784|          1589.0|                    0.0|            1589.0| 2017-03-25|      false|76561197962082784|     1910|        449|\n",
      "+--------+------+--------------+---------+--------+--------------------+-----------------+-----------------+-------------+-----------+-------------------+-------------+--------------+-----------------+---------------------------+-----------------+----------------+-----------------------+------------------+-----------+-----------+-----------------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = reviews.join(authors, on=reviews.author_steamid == authors.steamid, how='left')\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3f950f-c771-49a4-a99e-99dd623c6144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------------\n",
      " id                          | 20270143             \n",
      " app_id                      | 524220               \n",
      " appname                     | NieR:Automata™       \n",
      " review_id                   | 85124293             \n",
      " language                    | english              \n",
      " review                      | This game is so b... \n",
      " time_date_created           | 2021-01-22           \n",
      " time_date_updated           | 2021-01-22           \n",
      " votes_helpful               | 0                    \n",
      " votes_funny                 | 0                    \n",
      " weighted_vote_score         | 0.4330708384513855   \n",
      " comment_count               | 0                    \n",
      " steam_purchase              | true                 \n",
      " received_for_free           | false                \n",
      " written_during_early_access | false                \n",
      " author_steamid              | 76561198838897166    \n",
      " playtime_forever            | 128.0                \n",
      " playtime_last_two_weeks     | 0.0                  \n",
      " playtime_at_review          | 128.0                \n",
      " last_played                 | 2018-12-14           \n",
      " recommended                 | false                \n",
      " steamid                     | 76561198838897166    \n",
      " num_games                   | 107                  \n",
      " num_reviews                 | 76                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf10ac1-cad0-4b74-a7a3-59df9a34f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna({\n",
    "    'review': '',\n",
    "    'playtime_at_review': 0,\n",
    "    'playtime_forever': 0,\n",
    "    'playtime_last_two_weeks': 0,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8549bff-749b-42df-9340-c3b765956117",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'recommended' # rating\n",
    "\n",
    "data = data.withColumn(target, data[target].cast('integer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "634b12af-bcbe-4208-b8da-68a2fba280c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+\n",
      "|user_id|item_id|recommended|\n",
      "+-------+-------+-----------+\n",
      "| 9633.0|   49.0|          0|\n",
      "| 1777.0|   49.0|          0|\n",
      "| 7888.0|   49.0|          0|\n",
      "| 7266.0|   49.0|          0|\n",
      "| 1142.0|   49.0|          0|\n",
      "+-------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "# creating the pipeline\n",
    "user_indexer = StringIndexer(inputCol='steamid', outputCol=\"user_id\", handleInvalid=\"keep\")\n",
    "item_indexer = StringIndexer(inputCol='app_id', outputCol=\"item_id\", handleInvalid=\"keep\")\n",
    "\n",
    "pipeline = Pipeline(stages=[user_indexer, item_indexer])\n",
    "pipeline_model = pipeline.fit(data)\n",
    "\n",
    "transformed_df = pipeline_model.transform(data).select(['user_id', 'item_id', 'recommended'])\n",
    "transformed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88542a4a-ece6-4ebd-8181-c4f9bbf64af9",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2168eb89-0fe4-4e88-b437-5a264e05e7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 162716\n",
      "Test data size: 40802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(training_df, testing_df) = transformed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(\"Train data size:\", training_df.count())\n",
    "print(\"Test data size:\", testing_df.count())\n",
    "\n",
    "import os\n",
    "def run(command):\n",
    "    return os.popen(command).read()\n",
    "\n",
    "training_df.select(\"user_id\", \"item_id\", \"recommended\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/train\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/train/*.json > data/train.json\")\n",
    "\n",
    "testing_df.select(\"user_id\", \"item_id\", \"recommended\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"json\")\\\n",
    "    .save(\"project/data/test\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/data/test/*.json > data/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2ffe2-e245-4e83-8ebf-8a03d25f3fe3",
   "metadata": {},
   "source": [
    "## ML modeling\n",
    "\n",
    "For this project we will use ALS from pyspark and model using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6dd76e3-9412-4668-8a8a-0ca418568e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    maxIter=5,\n",
    "    rank=10,\n",
    "    regParam=0.01,\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"item_id\",\n",
    "    ratingCol=target,\n",
    "    coldStartStrategy=\"drop\",\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "model = als.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b86b27de-32b5-4b84-8a90-02c22bc7c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------+\n",
      "|user_id|item_id|recommended|  prediction|\n",
      "+-------+-------+-----------+------------+\n",
      "|   11.0|   92.0|          0|   0.5735925|\n",
      "|   22.0|   60.0|          0|   0.6468688|\n",
      "|   28.0|   49.0|          0|  0.28481925|\n",
      "|   50.0|   73.0|          0|  0.49654585|\n",
      "|   78.0|   60.0|          0|   0.9384319|\n",
      "|   83.0|   92.0|          0|  0.60724956|\n",
      "|   93.0|   73.0|          0|  -0.3578568|\n",
      "|  131.0|   92.0|          0|   0.5564618|\n",
      "|  152.0|   50.0|          0|  0.47348535|\n",
      "|  153.0|   50.0|          0|-0.026946994|\n",
      "+-------+-------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.transform(testing_df)\n",
    "\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "888a8f3f-2093-4339-9400-5e74c6653f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add calc_metrics and run functions\n",
    "from pyspark.sql.functions import col, expr\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "def calc_metrics(model, predictions, flat_recommendations=True, print_recommendations=True):\n",
    "    # calculate RMSE\n",
    "    evaluator = RegressionEvaluator(\n",
    "        metricName=\"rmse\", labelCol=\"recommended\", predictionCol=\"prediction\"\n",
    "    )\n",
    "    \n",
    "    # calculate Mean Average Precision and NDCG\n",
    "    app_recommendations = model.recommendForAllUsers(10)\n",
    "\n",
    "    # Create ground truth DataFrame containing actual interactions\n",
    "    ground_truth = testing_df.filter(col(target) == 1).groupBy(\"user_id\") \\\n",
    "        .agg(expr(\"collect_set(item_id) as actual_apps\"))\n",
    "\n",
    "    # Join recommendations with ground truth\n",
    "    recommendations_with_truth = app_recommendations.join(\n",
    "        ground_truth,\n",
    "        ground_truth.user_id == app_recommendations.user_id,\n",
    "        \"inner\"\n",
    "    )\n",
    "    recommendations_with_truth = recommendations_with_truth.select(\n",
    "        [app_recommendations.user_id, 'recommendations', 'actual_apps']\n",
    "    )\n",
    "\n",
    "    if flat_recommendations:\n",
    "        # Convert recommendations and actual_apps to lists\n",
    "        recommendations_with_truth = recommendations_with_truth.rdd.map(\n",
    "            lambda row: (\n",
    "                row.user_id,\n",
    "                [r.item_id for r in row.recommendations],\n",
    "                row.actual_apps\n",
    "            )\n",
    "        ).toDF([\"user_id\", \"recommendations\", \"actual_apps\"])\n",
    "    \n",
    "    if print_recommendations:\n",
    "        recommendations_with_truth.show(10, truncate=False)\n",
    "\n",
    "    # Compute RankingMetrics\n",
    "    metrics = RankingMetrics(recommendations_with_truth.rdd.map(\n",
    "        lambda row: (row.recommendations, row.actual_apps))\n",
    "    )\n",
    "    \n",
    "    # calculate all metrics\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    MAP = metrics.meanAveragePrecision\n",
    "    ndcg = metrics.ndcgAt(10)\n",
    "    \n",
    "    print(\"RMSE on test data:\", rmse)\n",
    "    print(\"Mean Average Precision (MAP):\", MAP)\n",
    "    print(\"NDCG at 5:\", ndcg)\n",
    "    \n",
    "    return rmse, MAP, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8422e0b7-f954-44df-975d-b9b413a07998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------+----------------------------------------+\n",
      "|user_id|recommendations                         |actual_apps                             |\n",
      "+-------+----------------------------------------+----------------------------------------+\n",
      "|769    |[41, 37, 76, 28, 65, 27, 42, 46, 77, 63]|[47.0, 72.0]                            |\n",
      "|3597   |[48, 72, 79, 94, 88, 60, 31, 68, 5, 80] |[28.0, 27.0, 62.0, 13.0, 78.0]          |\n",
      "|4142   |[22, 52, 43, 70, 61, 28, 44, 75, 4, 76] |[15.0, 23.0, 36.0, 44.0]                |\n",
      "|5776   |[27, 30, 50, 99, 76, 28, 57, 61, 44, 69]|[98.0, 65.0, 14.0, 32.0]                |\n",
      "|8649   |[32, 99, 45, 95, 67, 84, 92, 6, 91, 30] |[19.0]                                  |\n",
      "|576    |[23, 34, 9, 16, 72, 82, 55, 0, 65, 38]  |[83.0, 34.0, 33.0, 82.0]                |\n",
      "|1765   |[26, 92, 20, 57, 13, 18, 8, 63, 27, 1]  |[14.0, 18.0, 44.0]                      |\n",
      "|5136   |[49, 67, 36, 56, 21, 1, 31, 69, 11, 14] |[40.0, 69.0, 65.0, 51.0, 14.0, 3.0, 7.0]|\n",
      "|9499   |[22, 91, 52, 89, 88, 30, 47, 39, 75, 94]|[37.0, 6.0, 83.0]                       |\n",
      "|9829   |[45, 6, 52, 2, 30, 22, 74, 55, 86, 43]  |[28.0]                                  |\n",
      "+-------+----------------------------------------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE on test data: 0.4045570136725021\n",
      "Mean Average Precision (MAP): 0.03652132284266052\n",
      "NDCG at 5: 0.0766425245578284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4045570136725021, 0.03652132284266052, 0.0766425245578284)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metrics(model, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d483df4-e277-47f9-80d0-73665ccda0b1",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26a50fd7-6286-43eb-a946-ac9f64c3195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALSModel: uid=ALS_0999e54f8b2a, rank=5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator \n",
    "import numpy as np\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"recommended\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(als.maxIter, [5]) \\\n",
    "    .addGrid(als.rank, np.arange(5, 20+1, 5)) \\\n",
    "    .addGrid(als.regParam, np.linspace(0.01, 1, num=5)) \\\n",
    "    .addGrid(als.implicitPrefs, [False, True]) \\\n",
    "    .build()\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=param_grid,\n",
    "    evaluator=evaluator,\n",
    "    parallelism=5,\n",
    "    numFolds=3,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "cvModel = cv.fit(training_df)\n",
    "best_model1 = cvModel.bestModel\n",
    "best_model1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564438e5-1143-4ecc-84b7-999f29b57868",
   "metadata": {},
   "source": [
    "## Select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b707b24f-49b2-453b-bdff-8c9495d0b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='ALS_0999e54f8b2a', name='userCol', doc='column name for user ids. Ids must be within the integer value range.'): 'user_id',\n",
      " Param(parent='ALS_0999e54f8b2a', name='itemCol', doc='column name for item ids. Ids must be within the integer value range.'): 'item_id',\n",
      " Param(parent='ALS_0999e54f8b2a', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
      " Param(parent='ALS_0999e54f8b2a', name='blockSize', doc='block size for stacking input data in matrices. Data is stacked within partitions. If block size is more than remaining data in a partition then it is adjusted to the size of this data.'): 4096,\n",
      " Param(parent='ALS_0999e54f8b2a', name='coldStartStrategy', doc=\"strategy for dealing with unknown or new users/items at prediction time. This may be useful in cross-validation or production scenarios, for handling user/item ids the model has not seen in the training data. Supported values: 'nan', 'drop'.\"): 'drop'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(best_model1.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5de7158b-4b8c-4cb3-97b2-0162f25ada18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+----------+\n",
      "|user_id|item_id|recommended|prediction|\n",
      "+-------+-------+-----------+----------+\n",
      "|   11.0|   92.0|          0| 0.4386111|\n",
      "|   22.0|   60.0|          0| 0.6223034|\n",
      "|   28.0|   49.0|          0|0.56308067|\n",
      "|   50.0|   73.0|          0| 0.6733649|\n",
      "|   78.0|   60.0|          0|0.91516465|\n",
      "+-------+-------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_predictions1 = best_model1.transform(testing_df)\n",
    "best_predictions1.show(5)\n",
    "\n",
    "best_predictions1.select(\"recommended\", \"prediction\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .save(\"project/output/model1_predictions.csv\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/output/model1_predictions.csv/*.csv > output/model1_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b4d5674-407a-4866-923d-25eb50915c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------+---------------------------------------------------------------------------+\n",
      "|user_id|recommendations                         |actual_apps                                                                |\n",
      "+-------+----------------------------------------+---------------------------------------------------------------------------+\n",
      "|28     |[32, 92, 89, 36, 86, 78, 79, 16, 77, 84]|[42.0, 20.0, 6.0, 79.0, 31.0, 80.0, 29.0]                                  |\n",
      "|31     |[22, 20, 4, 91, 52, 19, 83, 36, 75, 6]  |[9.0, 23.0, 5.0, 75.0, 1.0, 12.0, 52.0, 83.0, 81.0, 79.0, 13.0, 84.0, 72.0]|\n",
      "|34     |[78, 12, 21, 31, 75, 40, 93, 1, 7, 46]  |[68.0, 36.0, 1.0, 48.0, 6.0, 83.0, 55.0, 31.0, 18.0, 44.0]                 |\n",
      "|53     |[36, 92, 72, 78, 79, 75, 81, 4, 6, 54]  |[0.0, 2.0, 19.0, 34.0, 78.0]                                               |\n",
      "|65     |[45, 73, 89, 65, 95, 67, 23, 29, 77, 54]|[15.0, 8.0, 1.0, 49.0, 95.0, 47.0, 74.0]                                   |\n",
      "|78     |[30, 66, 9, 98, 59, 12, 51, 25, 68, 31] |[73.0, 22.0, 35.0, 12.0, 92.0, 77.0, 55.0]                                 |\n",
      "|81     |[66, 84, 71, 48, 92, 3, 42, 0, 41, 99]  |[5.0, 36.0, 95.0, 6.0]                                                     |\n",
      "|85     |[22, 97, 87, 26, 13, 91, 62, 35, 58, 56]|[52.0, 65.0, 19.0, 95.0, 27.0, 85.0, 61.0, 81.0, 43.0]                     |\n",
      "|101    |[5, 67, 73, 45, 88, 95, 81, 65, 72, 47] |[42.0, 70.0, 21.0, 28.0, 48.0, 24.0, 13.0]                                 |\n",
      "|108    |[73, 45, 57, 30, 50, 28, 29, 85, 96, 74]|[70.0, 54.0, 19.0, 50.0, 28.0, 27.0, 6.0, 89.0, 62.0, 33.0]                |\n",
      "+-------+----------------------------------------+---------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE on test data: 0.36869138717155947\n",
      "Mean Average Precision (MAP): 0.031177691995329694\n",
      "NDCG at 5: 0.0671031605304494\n"
     ]
    }
   ],
   "source": [
    "rmse1, map1, ndcg1 = calc_metrics(best_model1, best_predictions1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5fa2b-0604-4f5c-8604-f9e15c048ba5",
   "metadata": {},
   "source": [
    "Only RMSE improved after Hyperparameter optimization\n",
    "- from (0.4045) -> to (0.3686)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37471e3f-8f5a-489a-bd81-bb9319402d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving model\n",
    "best_model1.write().overwrite().save(\"project/models/model1\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -get project/models/model1 models/model1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded3d0ee-440e-4b3e-b3ab-add1c9869e82",
   "metadata": {},
   "source": [
    "# Model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f05c197d-dcf9-4681-8620-0de2e8358700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "class Model2:\n",
    "    def __init__(\n",
    "        self,\n",
    "        userCol,\n",
    "        itemCol,\n",
    "        ratingCol,\n",
    "        num_rank=10,\n",
    "    ):\n",
    "        self.userCol = userCol\n",
    "        self.itemCol = itemCol\n",
    "        self.ratingCol = ratingCol\n",
    "        self.num_rank = num_rank\n",
    "        \n",
    "        self.id2item = {}\n",
    "\n",
    "    def fit(self, df):\n",
    "        # assign for each item and user it ids\n",
    "        df = df.withColumn(\"model_user_id\", F.dense_rank().over(Window.orderBy(self.userCol))-1)\n",
    "        df = df.withColumn(\"model_item_id\", F.dense_rank().over(Window.orderBy(self.itemCol))-1)\n",
    "\n",
    "        # get number of items\n",
    "        self.num_items = df.select(self.itemCol).distinct().count()\n",
    "\n",
    "        # Convert the DataFrame into user-item matrix\n",
    "        user_item_rdd = df.rdd.map(lambda row: (\n",
    "            row['model_user_id'], (row['model_item_id'], row[self.ratingCol])\n",
    "        ))\n",
    "        grouped_user_item_rdd = user_item_rdd.groupByKey().mapValues(list)\n",
    "        grouped_user_item_rdd = grouped_user_item_rdd.map(\n",
    "            self._get_sparse_vector\n",
    "        )\n",
    "        \n",
    "        # Compute SVD\n",
    "        self.mat = RowMatrix(grouped_user_item_rdd)\n",
    "        svd = self.mat.computeSVD(k=self.num_rank, computeU=True)\n",
    "\n",
    "        # save U, s, V martrices\n",
    "        self.user_vectors = np.array([vec.toArray() for vec in svd.U.rows.collect()])\n",
    "        self.item_V = svd.V.toArray()\n",
    "        self.singular_values = svd.s.toArray()\n",
    "        self.df = df  # save this dataframe\n",
    "\n",
    "        # save id2item, id2user, item2id, user2id dict\n",
    "        self.id2item = {row[0]: row[1] for row in self.df.select(['model_item_id', self.itemCol]).collect()}\n",
    "        self.id2user = {row[0]: row[1] for row in self.df.select(['model_user_id', self.userCol]).collect()}\n",
    "        self.item2id = {v: k for k, v in self.id2item.items()}\n",
    "        self.user2id = {v: k for k, v in self.id2user.items()}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _get_sparse_vector(self, row):\n",
    "        _, item_ratings = row\n",
    "        sparse = {}\n",
    "        for item_id, rating in item_ratings:\n",
    "            if rating > 0:\n",
    "                sparse[item_id] = rating\n",
    "\n",
    "        return SparseVector(self.num_items, sparse)\n",
    "\n",
    "    def transform(self, testing_df):\n",
    "        # for each user item pair predict the rating\n",
    "        user_item = [(row[0], row[1], row[2]) for row in testing_df.select([self.userCol, self.itemCol, self.ratingCol]).collect()]\n",
    "        df = []\n",
    "        for u, i, r in user_item:\n",
    "            if u not in self.user2id:\n",
    "                continue\n",
    "            df.append([u, i, r, float(self.recommendForUser(u, num_recommendations=self.num_items)[int(i)][0])])\n",
    "        \n",
    "        schema = StructType([\n",
    "            StructField(\"user_id\", FloatType(), True),\n",
    "            StructField(\"item_id\", FloatType(), True),\n",
    "            StructField(\"recommended\", IntegerType(), True),\n",
    "            StructField(\"prediction\", FloatType(), True),\n",
    "        ])\n",
    "        return self.df.sql_ctx.createDataFrame(df, schema=schema)\n",
    "\n",
    "    def recommendForUser(self, user_id, num_recommendations=10):\n",
    "        # check for user id\n",
    "        model_user_id = self.user2id.get(user_id, None)\n",
    "        if model_user_id is None:\n",
    "            raise ValueError(f\"given user_id ({user_id}) does not exists\")\n",
    "\n",
    "        predictions = np.dot(self.user_vectors[model_user_id], np.dot(np.diag(self.singular_values), self.item_V.T))\n",
    "        predictions = sorted(zip(predictions, self.item2id.keys()), reverse=True)[:num_recommendations]\n",
    "        return predictions\n",
    "\n",
    "    def recommendForAllUsers(self, num_recommendations=10, return_scores=False):\n",
    "        predictions = np.dot(self.user_vectors, np.dot(np.diag(self.singular_values), self.item_V.T))\n",
    "        predictions = [sorted(zip(p, self.item2id.keys()), reverse=True)[:num_recommendations] for p in predictions]\n",
    "        if return_scores:\n",
    "            return predictions\n",
    "\n",
    "        predictions = [[item for sc, item in p] for p in predictions]\n",
    "        return self.df.sql_ctx.createDataFrame(zip(self.user2id.keys(), predictions), ['user_id', 'recommendations'])\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"SVD: k={self.num_rank}\"\n",
    "    \n",
    "    def save_weights(self, path):\n",
    "        try:\n",
    "            # save matrices produced after computeSVD\n",
    "            self.mat.rows.toDF().write().overwrite().save(path)\n",
    "        except:\n",
    "            print(\"Could not save the weights.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "301ed582-5558-401c-80de-550e0d1f5659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model2 at 0x7fba5c8ed550>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train second model\n",
    "model2 = Model2(\n",
    "    userCol='user_id',\n",
    "    itemCol='item_id',\n",
    "    ratingCol='recommended',\n",
    "    num_rank=10,\n",
    ")\n",
    "\n",
    "model2.fit(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e609bc8-82ef-4ec3-9e1e-82592506e1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------+\n",
      "|user_id|item_id|recommended|  prediction|\n",
      "+-------+-------+-----------+------------+\n",
      "|   11.0|   92.0|          0|5.4368563E-4|\n",
      "|   22.0|   60.0|          0|  0.21060102|\n",
      "|   28.0|   49.0|          0|   0.2026345|\n",
      "|   50.0|   73.0|          0|  0.19939877|\n",
      "|   78.0|   60.0|          0|   0.1064963|\n",
      "|   83.0|   92.0|          0| 0.102369994|\n",
      "|   93.0|   73.0|          0|  0.14978652|\n",
      "|  131.0|   92.0|          0| 0.026052501|\n",
      "|  152.0|   50.0|          0|  0.15982084|\n",
      "|  153.0|   50.0|          0|  0.20711921|\n",
      "+-------+-------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict on test set\n",
    "model2_predictions = model2.transform(testing_df)\n",
    "model2_predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dbf36513-4ef3-4d43-8a48-8d25df79d8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
      "|user_id|recommendations                                          |actual_apps                                                                                   |\n",
      "+-------+---------------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
      "|0.0    |[9.0, 8.0, 4.0, 1.0, 19.0, 14.0, 0.0, 25.0, 7.0, 15.0]   |[42.0, 2.0, 15.0, 37.0, 54.0, 65.0, 60.0, 18.0, 7.0, 44.0, 72.0]                              |\n",
      "|1.0    |[4.0, 12.0, 21.0, 8.0, 0.0, 11.0, 5.0, 1.0, 2.0, 28.0]   |[70.0, 68.0, 36.0, 19.0, 6.0, 62.0, 55.0, 29.0, 5.0, 86.0, 27.0, 46.0, 26.0, 89.0, 81.0, 44.0]|\n",
      "|2.0    |[5.0, 14.0, 4.0, 1.0, 12.0, 7.0, 11.0, 25.0, 9.0, 0.0]   |[5.0, 37.0, 73.0, 48.0, 45.0, 26.0, 14.0, 84.0, 7.0, 80.0]                                    |\n",
      "|3.0    |[7.0, 13.0, 3.0, 9.0, 14.0, 18.0, 5.0, 0.0, 12.0, 1.0]   |[70.0, 15.0, 73.0, 53.0, 4.0, 85.0, 60.0, 79.0, 34.0]                                         |\n",
      "|4.0    |[9.0, 7.0, 1.0, 15.0, 5.0, 14.0, 8.0, 4.0, 31.0, 25.0]   |[39.0, 5.0, 67.0, 46.0, 85.0, 14.0, 59.0, 13.0, 18.0]                                         |\n",
      "|5.0    |[7.0, 12.0, 11.0, 13.0, 14.0, 18.0, 5.0, 1.0, 3.0, 8.0]  |[21.0, 27.0, 10.0, 62.0, 61.0, 13.0, 18.0, 16.0]                                              |\n",
      "|6.0    |[0.0, 10.0, 12.0, 14.0, 9.0, 11.0, 5.0, 15.0, 27.0, 17.0]|[40.0, 23.0, 15.0, 22.0, 27.0, 45.0, 87.0, 83.0, 3.0, 30.0, 29.0, 16.0]                       |\n",
      "|7.0    |[14.0, 9.0, 13.0, 18.0, 3.0, 7.0, 1.0, 5.0, 25.0, 0.0]   |[0.0, 41.0, 75.0, 86.0, 6.0, 83.0, 14.0, 3.0, 13.0, 82.0]                                     |\n",
      "|8.0    |[1.0, 11.0, 10.0, 12.0, 0.0, 7.0, 4.0, 5.0, 21.0, 15.0]  |[36.0, 53.0, 48.0, 47.0, 6.0, 57.0, 32.0, 31.0, 55.0]                                         |\n",
      "|9.0    |[4.0, 1.0, 9.0, 19.0, 8.0, 15.0, 2.0, 5.0, 20.0, 23.0]   |[68.0, 66.0, 39.0, 5.0, 67.0, 50.0, 4.0, 45.0, 24.0, 81.0, 60.0, 29.0]                        |\n",
      "+-------+---------------------------------------------------------+----------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "RMSE on test data: 0.7617843383809006\n",
      "Mean Average Precision (MAP): 0.061759351244201954\n",
      "NDCG at 5: 0.11854677327476618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7617843383809006, 0.061759351244201954, 0.11854677327476618)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metrics(model2, model2_predictions, flat_recommendations=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4367f0-d45f-484d-8ed3-6919b5e1c536",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "296a59a0-9e25-42f6-8bdc-ffe76521f489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:28<01:52, 28.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.7604228716624235\n",
      "Mean Average Precision (MAP): 0.06494935320897477\n",
      "NDCG at 5: 0.12474180524892531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:57<01:26, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.7617843383826255\n",
      "Mean Average Precision (MAP): 0.061759351244201954\n",
      "NDCG at 5: 0.11854677327476618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:32<01:03, 31.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.7645104068235493\n",
      "Mean Average Precision (MAP): 0.0601257213067417\n",
      "NDCG at 5: 0.11536137131376646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [02:19<00:37, 37.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.7674062697022306\n",
      "Mean Average Precision (MAP): 0.057699906700114933\n",
      "NDCG at 5: 0.11181078544795109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:59<00:00, 35.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data: 0.7720928761555658\n",
      "Mean Average Precision (MAP): 0.05505272788068843\n",
      "NDCG at 5: 0.10732104658072225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# parameters to optimizer\n",
    "param_k = [5, 10, 15, 20, 30]\n",
    "\n",
    "models = []\n",
    "for k in tqdm(param_k, total=len(param_k)):\n",
    "    model2_init = Model2(userCol='user_id', itemCol='item_id', ratingCol='recommended', num_rank=k)\n",
    "    model2_init.fit(training_df)\n",
    "    predictions = model2_init.transform(testing_df)\n",
    "    \n",
    "    rmse, MAP, NDCG = calc_metrics(model2_init, predictions, print_recommendations=False, flat_recommendations=False)\n",
    "    models.append({\n",
    "        'rmse': rmse,\n",
    "        'MAP': MAP,\n",
    "        'NDCG': NDCG,\n",
    "        'k': k,\n",
    "        'model': model2_init,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b65707a-4b21-4a75-8155-02e3b588b0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics for k=5 rmse2=0.7604228716624235, map2=0.06494935320897477, ndcg2=0.12474180524892531\n"
     ]
    }
   ],
   "source": [
    "best_model2 = min(models, key=lambda x: x['rmse'])\n",
    "rmse2 = best_model2['rmse']\n",
    "map2 = best_model2['MAP']\n",
    "ndcg2 = best_model2['NDCG']\n",
    "k = best_model2['k']\n",
    "best_model2 = best_model2['model']\n",
    "print(f\"metrics for k={k} rmse2={rmse2}, map2={map2}, ndcg2={ndcg2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63550548-db8f-4fb6-bc64-67fa16bce033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+------------+\n",
      "|user_id|item_id|recommended|  prediction|\n",
      "+-------+-------+-----------+------------+\n",
      "|   11.0|   92.0|          0| 0.028685931|\n",
      "|   22.0|   60.0|          0|  0.20716113|\n",
      "|   28.0|   49.0|          0|  0.20613548|\n",
      "|   50.0|   73.0|          0|  0.18521795|\n",
      "|   78.0|   60.0|          0|  0.09038921|\n",
      "|   83.0|   92.0|          0|  0.12898695|\n",
      "|   93.0|   73.0|          0|  0.14464976|\n",
      "|  131.0|   92.0|          0|-0.017386159|\n",
      "|  152.0|   50.0|          0|  0.17366536|\n",
      "|  153.0|   50.0|          0|  0.21284482|\n",
      "+-------+-------+-----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on test set\n",
    "model2_predictions = best_model2.transform(testing_df)\n",
    "model2_predictions.show(10)\n",
    "\n",
    "model2_predictions.select(\"recommended\", \"prediction\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .save(\"project/output/model2_predictions.csv\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/output/model2_predictions.csv/*.csv > output/model2_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bed1bdb6-62b2-4f08-a5de-2effe5b41e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not save the weights.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model2.save_weights('project/models/model2')\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -get project/models/model2 models/model2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d3ab6-4de4-472d-9273-52464f91cc9f",
   "metadata": {},
   "source": [
    "# Compare best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c433be0-c7b6-47d9-9ff8-defff640f7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-------------------+--------------------+-------------------+\n",
      "|model                                 |RMSE               |MAP                 |NDCG               |\n",
      "+--------------------------------------+-------------------+--------------------+-------------------+\n",
      "|ALSModel: uid=ALS_0999e54f8b2a, rank=5|0.36869138717155947|0.031177691995329694|0.0671031605304494 |\n",
      "|SVD: k=5                              |0.7604228716624235 |0.06494935320897477 |0.12474180524892531|\n",
      "+--------------------------------------+-------------------+--------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 36642)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 320, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 351, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 364, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib64/python3.6/socketserver.py\", line 724, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create data frame to report performance of the models\n",
    "models = [[str(best_model1).replace(\",\", \"|\"), rmse1, map1, ndcg1], [str(best_model2), rmse2, map2, ndcg2]]\n",
    "\n",
    "evaluation_results = spark.createDataFrame(models, [\"model\", \"RMSE\", \"MAP\", \"NDCG\"])\n",
    "evaluation_results.show(truncate=False)\n",
    "\n",
    "# Save it to HDFS\n",
    "evaluation_results.coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .save(\"project/output/evaluation.csv\")\n",
    "\n",
    "# Run it from root directory of the repository\n",
    "run(\"hdfs dfs -cat project/output/evaluation.csv/*.csv > output/evaluation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
